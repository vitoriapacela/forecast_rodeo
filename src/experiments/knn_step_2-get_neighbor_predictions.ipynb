{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get KNN neighbor predictions\n",
    "\n",
    "Generates the predictions of the most similar viable neighbors for all dates based on saved KNN similarities (generated by knn_step_1-compute_similarities.ipynb) and saves the predictions to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Package loading\n",
    "\n",
    "# Autoreload packages that are modified\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Plotting magic\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load relevant packages\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import *\n",
    "import sys\n",
    "import subprocess\n",
    "from datetime import datetime, timedelta\n",
    "import netCDF4\n",
    "import time\n",
    "from functools import partial\n",
    "import os\n",
    "\n",
    "if os.path.basename(os.getcwd()) == \"experiments\":\n",
    "    os.chdir(os.path.join(\"..\",\"..\"))\n",
    "\n",
    "# Adds 'experiments' folder to path to load experiments_util\n",
    "sys.path.insert(0, 'src/experiments')\n",
    "# Load general utility functions\n",
    "from experiments_util import *\n",
    "# Load functionality for fitting and predicting\n",
    "from fit_and_predict import *\n",
    "# Load functionality for evaluation\n",
    "from skill import *\n",
    "# Load functionality for knn\n",
    "from knn_util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323\n"
     ]
    }
   ],
   "source": [
    "# Output experiment name determined by inputs above\n",
    "experiment = \"knn\"\n",
    "# the variable to be predicted\n",
    "gt_id = \"contest_tmp2m\" # \"contest_precip\" or \"contest_tmp2m\"\n",
    "# Prediction horizon\n",
    "target_horizon = \"56w\" # \"34w\" or \"56w\"\n",
    "# The number of past days that should contribute to measure of similarity\n",
    "past_days = 60\n",
    "# Only use measurements available this many days prior to \n",
    "# official contest submission date\n",
    "days_early = 365 - (14 + get_forecast_delta(target_horizon, days_early = 0)) \n",
    "print(days_early)\n",
    "# Maximum number of neighbors\n",
    "max_num_nbrs = 20\n",
    "\n",
    "## Process inputs\n",
    "\n",
    "# Identify measurement variable name\n",
    "measurement_variable = get_measurement_variable(gt_id) # 'tmp2m' or 'prate'\n",
    "\n",
    "# column names for gt_col, clim_col and anom_col \n",
    "gt_col = measurement_variable\n",
    "clim_col = measurement_variable+\"_clim\"\n",
    "anom_col = get_measurement_variable(gt_id)+\"_anom\" # 'tmp2m_anom' or 'prate_anom'\n",
    "\n",
    "# nbr_start_delta = minimum number of days between start date of most recent neighbor to consider\n",
    "# (aggregation_days = 2 weeks to observe complete measurement) and start date of target period \n",
    "# (2 or 4 weeks plus days early days ahead)\n",
    "aggregation_days = 14\n",
    "nbr_start_delta = (aggregation_days + \n",
    "                   get_forecast_delta(target_horizon, days_early = days_early))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting contest_tmp2m_shiftNone with anomalies\n",
      "Elapsed: 10.837227821350098s\n",
      "Elapsed time: 9.075320 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Load ground truth anomalies (using complete climatology)\n",
    "#\n",
    "anoms = get_lat_lon_date_features(anom_ids = [gt_id], first_year=get_first_year(gt_id))\n",
    "# Drop unnecessary columns\n",
    "anoms = anoms.loc[:,['lat','lon','start_date',gt_col,anom_col,clim_col]]\n",
    "# Pivot dataframe to have one row per start date\n",
    "tic(); anoms = anoms.set_index(['lat','lon','start_date']).unstack(['lat','lon']); toc()\n",
    "# Drop start dates that have no measurements (e.g., leap days, which have no climatology)\n",
    "anoms = anoms.dropna(axis='index', how='all')\n",
    "tic()\n",
    "# Determine which neighbor start_dates are viable\n",
    "viable_neighbors = anoms.index\n",
    "# Stack anoms dataframe to have lat, lon, start_date columns\n",
    "anoms = anoms.stack(['lat','lon']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading viable similarities from  results/knn/shared/viable_similarities-contest_tmp2m-56w-days60-early323.h5\n",
      "Elapsed time: 0.609106 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read viable similarities from disk\n",
    "cache_dir = os.path.join(\"results\", experiment, \"shared\")\n",
    "viable_similarities_file = os.path.join(\n",
    "    cache_dir,'viable_similarities-{}-{}-days{}-early{}.h5'.format(gt_id,target_horizon,past_days,days_early))\n",
    "print(\"Reading viable similarities from \", viable_similarities_file); tic()\n",
    "viable_similarities = pd.read_hdf(viable_similarities_file); toc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Form and save neighbor predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/network/home/barinpvi/.conda/envs/geo/lib/python3.6/site-packages/pandas/core/frame.py:6692: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1981-01-01 00:00:00\n",
      "1982-01-01 00:00:00\n",
      "1983-01-01 00:00:00\n",
      "1984-01-01 00:00:00\n",
      "1985-01-01 00:00:00\n",
      "1986-01-01 00:00:00\n",
      "1987-01-01 00:00:00\n",
      "1988-01-01 00:00:00\n",
      "1989-01-01 00:00:00\n",
      "1990-01-01 00:00:00\n",
      "1991-01-01 00:00:00\n",
      "1992-01-01 00:00:00\n",
      "1993-01-01 00:00:00\n",
      "1994-01-01 00:00:00\n",
      "1995-01-01 00:00:00\n",
      "1996-01-01 00:00:00\n",
      "1997-01-01 00:00:00\n",
      "1998-01-01 00:00:00\n",
      "1999-01-01 00:00:00\n",
      "2000-01-01 00:00:00\n",
      "2001-01-01 00:00:00\n",
      "2002-01-01 00:00:00\n",
      "2003-01-01 00:00:00\n",
      "2004-01-01 00:00:00\n",
      "2005-01-01 00:00:00\n",
      "2006-01-01 00:00:00\n",
      "2007-01-01 00:00:00\n",
      "2008-01-01 00:00:00\n",
      "2009-01-01 00:00:00\n",
      "2010-01-01 00:00:00\n",
      "2011-01-01 00:00:00\n",
      "2012-01-01 00:00:00\n",
      "2013-01-01 00:00:00\n",
      "2014-01-01 00:00:00\n",
      "2015-01-01 00:00:00\n",
      "2016-01-01 00:00:00\n",
      "2017-01-01 00:00:00\n",
      "2018-01-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Form predictions\n",
    "#\n",
    "\n",
    "# Prepare dataframes for storing predictions and similarities\n",
    "preds = pd.DataFrame(columns = ['lat','lon','start_date']+['knn'+str(i+1) for i in range(max_num_nbrs)])\n",
    "\n",
    "# Target dates are dates for which viable similarities are not all NaN\n",
    "all_target_dates = viable_similarities.loc[~viable_similarities.isnull().all(axis=1)].index\n",
    "\n",
    "# Process results from each year\n",
    "for target in all_target_dates:\n",
    "    # Find the neighbors\n",
    "    nbrs = get_target_neighbors(\n",
    "        target, target_horizon, gt_id, \n",
    "        nbr_start_delta, past_days, viable_similarities, False,\n",
    "        False)[0:max_num_nbrs]\n",
    "\n",
    "    if nbrs.size != max_num_nbrs:\n",
    "        continue\n",
    "        \n",
    "    # Get predictions of each neighbor\n",
    "    nbr_preds = anoms.loc[anoms.start_date.isin(nbrs), ['lat','lon','start_date',anom_col]].copy()\n",
    "    nbr_preds_wide = nbr_preds.pivot_table(index=['lat','lon'], columns='start_date')\n",
    "    nbr_dates = nbr_preds_wide.columns.levels[1]\n",
    "    nbr_preds_wide = pd.DataFrame(nbr_preds_wide.to_records())\n",
    "    nbr_preds_wide.columns = ['lat','lon'] + nbr_dates.tolist()\n",
    "    \n",
    "    # Reorder columns in order of most similar to least similar neighbor\n",
    "    nbr_preds_wide = nbr_preds_wide.loc[:,['lat','lon'] + nbrs.tolist()]\n",
    "    nbr_preds_wide.columns = ['lat','lon'] + ['knn'+str(i+1) for i in range(max_num_nbrs)]\n",
    "    \n",
    "    # Associate with target date\n",
    "    nbr_preds_wide['start_date'] = target\n",
    "    \n",
    "    # Store predictions\n",
    "    preds = preds.append(nbr_preds_wide)\n",
    "    \n",
    "    if target.month == 1 and target.day == 1:\n",
    "        print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving predictions to  results/knn/knn-contest_tmp2m-56w-days60-early323-maxnbrs20.h5\n",
      "Elapsed time: 15.193359 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save results to file\n",
    "cache_dir = os.path.join('results', experiment)\n",
    "if not os.path.isdir(cache_dir):\n",
    "    os.makedirs(cache_dir)\n",
    "preds_file = os.path.join(\n",
    "    cache_dir,'knn-{}-{}-days{}-early{}-maxnbrs{}.h5'.format(gt_id,target_horizon,past_days,days_early,max_num_nbrs))\n",
    "print(\"Saving predictions to \", preds_file); tic()\n",
    "preds.to_hdf(preds_file, key=\"data\", mode=\"w\"); toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
